{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-05T08:17:59.072718200Z",
     "start_time": "2025-02-05T08:17:58.853746500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 加载乳腺癌数据集\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 60\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m activation \u001B[38;5;129;01min\u001B[39;00m activations:\n\u001B[0;32m     59\u001B[0m     model \u001B[38;5;241m=\u001B[39m CustomMLPClassifier(activation\u001B[38;5;241m=\u001B[39mactivation, hidden_layer_sizes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m32\u001B[39m), max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test_scaled)\n\u001B[0;32m     62\u001B[0m     y_scores \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(X_test_scaled)[:, \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32mE:\\Hawkes\\CudaTest\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Hawkes\\CudaTest\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:751\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    734\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[0;32m    735\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001B[39;00m\n\u001B[0;32m    736\u001B[0m \n\u001B[0;32m    737\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    749\u001B[0m \u001B[38;5;124;03m        Returns a trained MLP model.\u001B[39;00m\n\u001B[0;32m    750\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mincremental\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Hawkes\\CudaTest\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:475\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron._fit\u001B[1;34m(self, X, y, incremental)\u001B[0m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;66;03m# Run the Stochastic optimization solver\u001B[39;00m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver \u001B[38;5;129;01min\u001B[39;00m _STOCHASTIC_SOLVERS:\n\u001B[1;32m--> 475\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_stochastic\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeltas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoef_grads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mintercept_grads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_units\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mincremental\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    486\u001B[0m \u001B[38;5;66;03m# Run the LBFGS solver\u001B[39;00m\n\u001B[0;32m    487\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlbfgs\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mE:\\Hawkes\\CudaTest\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:633\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron._fit_stochastic\u001B[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)\u001B[0m\n\u001B[0;32m    630\u001B[0m     y_batch \u001B[38;5;241m=\u001B[39m y[batch_slice]\n\u001B[0;32m    632\u001B[0m activations[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m X_batch\n\u001B[1;32m--> 633\u001B[0m batch_loss, coef_grads, intercept_grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backprop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m    \u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    637\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdeltas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    638\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef_grads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    639\u001B[0m \u001B[43m    \u001B[49m\u001B[43mintercept_grads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    640\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    641\u001B[0m accumulated_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m batch_loss \u001B[38;5;241m*\u001B[39m (\n\u001B[0;32m    642\u001B[0m     batch_slice\u001B[38;5;241m.\u001B[39mstop \u001B[38;5;241m-\u001B[39m batch_slice\u001B[38;5;241m.\u001B[39mstart\n\u001B[0;32m    643\u001B[0m )\n\u001B[0;32m    645\u001B[0m \u001B[38;5;66;03m# update weights\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Hawkes\\CudaTest\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:326\u001B[0m, in \u001B[0;36mBaseMultilayerPerceptron._backprop\u001B[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001B[0m\n\u001B[0;32m    323\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    325\u001B[0m \u001B[38;5;66;03m# Forward propagate\u001B[39;00m\n\u001B[1;32m--> 326\u001B[0m activations \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[38;5;66;03m# Get loss\u001B[39;00m\n\u001B[0;32m    329\u001B[0m loss_func_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss\n",
      "Cell \u001B[1;32mIn[5], line 28\u001B[0m, in \u001B[0;36mCustomMLPClassifier._forward_pass\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     26\u001B[0m activations \u001B[38;5;241m=\u001B[39m [X]\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoefs_)):\n\u001B[1;32m---> 28\u001B[0m     hidden_activation \u001B[38;5;241m=\u001B[39m \u001B[43mactivations\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoefs_\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercepts_[i]\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcustom_activation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleaky_relu\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     30\u001B[0m         activations\u001B[38;5;241m.\u001B[39mappend(leaky_relu(hidden_activation))\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n",
    "\n",
    "# 定义激活函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def leaky_relu(x):\n",
    "    return np.where(x > 0, x, 0.01 * x)\n",
    "\n",
    "def swish(x):\n",
    "    return x * sigmoid(x)\n",
    "\n",
    "# 自定义激活函数的 MLPClassifier\n",
    "class CustomMLPClassifier(MLPClassifier):\n",
    "    def __init__(self, activation='relu', hidden_layer_sizes=(100,), **kwargs):\n",
    "        super().__init__(activation=activation, hidden_layer_sizes=hidden_layer_sizes, **kwargs)\n",
    "        self.custom_activation = activation\n",
    "\n",
    "    def _forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        for i in range(len(self.coefs_)):\n",
    "            hidden_activation = activations[-1] @ self.coefs_[i] + self.intercepts_[i]\n",
    "            if self.custom_activation == 'leaky_relu':\n",
    "                activations.append(leaky_relu(hidden_activation))\n",
    "            elif self.custom_activation == 'swish':\n",
    "                activations.append(swish(hidden_activation))\n",
    "            else:\n",
    "                activations.append(super().activation(hidden_activation))\n",
    "        return activations[-1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations = self._forward_pass(X)\n",
    "        if self.out_activation_ == 'softmax':\n",
    "            return np.argmax(activations, axis=1)\n",
    "        else:\n",
    "            return activations > 0.5\n",
    "\n",
    "# 数据加载与预处理\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 激活函数列表\n",
    "activations = ['relu', 'tanh', 'logistic', 'leaky_relu', 'swish']\n",
    "\n",
    "# 训练模型并评估性能\n",
    "results = []\n",
    "for activation in activations:\n",
    "    model = CustomMLPClassifier(activation=activation, hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_scores = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    results.append({\n",
    "        'activation': activation,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    })\n",
    "    print(f\"Activation: {activation}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "# 绘制 ROC 曲线\n",
    "plt.figure(figsize=(10, 8))\n",
    "for result in results:\n",
    "    plt.plot(result['fpr'], result['tpr'], label=f\"{result['activation']} (AUC = {result['roc_auc']:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Different Activation Functions')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 绘制激活函数图像\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "plt.figure(figsize=(10, 8))\n",
    "for activation in activations:\n",
    "    if activation == 'relu':\n",
    "        y = np.maximum(x, 0)\n",
    "    elif activation == 'tanh':\n",
    "        y = np.tanh(x)\n",
    "    elif activation == 'logistic':\n",
    "        y = sigmoid(x)\n",
    "    elif activation == 'leaky_relu':\n",
    "        y = leaky_relu(x)\n",
    "    elif activation == 'swish':\n",
    "        y = swish(x)\n",
    "    plt.plot(x, y, label=activation)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Activation')\n",
    "plt.title('Activation Functions')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T08:20:31.063720800Z",
     "start_time": "2025-02-05T08:20:30.908465800Z"
    }
   },
   "id": "aab7d4164cc5bac3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "83a464a15c6733bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
